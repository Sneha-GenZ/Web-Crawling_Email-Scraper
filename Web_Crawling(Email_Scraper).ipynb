{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sneha-GenZ/Web-Crawling_Email-Scraper/blob/main/Web_Crawling(Email_Scraper).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:04:35.948026Z",
          "iopub.status.busy": "2022-12-26T10:04:35.947633Z",
          "iopub.status.idle": "2022-12-26T10:05:06.892132Z",
          "shell.execute_reply": "2022-12-26T10:05:06.890969Z",
          "shell.execute_reply.started": "2022-12-26T10:04:35.947994Z"
        },
        "trusted": true,
        "id": "FNq6jU_HjaG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a808d6b-976d-4c4d-a9d0-6387dead4504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.31.0)\n",
            "Collecting pyquery (from requests-html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests-html)\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Collecting parse (from requests-html)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting bs4 (from requests-html)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting w3lib (from requests-html)\n",
            "  Downloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests-html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2024.6.2)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (7.1.0)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.66.4)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.12.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.4)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.19.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.5)\n",
            "Installing collected packages: parse, fake-useragent, appdirs, websockets, w3lib, urllib3, pyee, cssselect, pyquery, pyppeteer, bs4, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed appdirs-1.4.4 bs4-0.0.2 cssselect-1.2.0 fake-useragent-1.5.1 parse-1.20.2 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests-html-0.10.0 urllib3-1.26.19 w3lib-2.2.1 websockets-10.4\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.6.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests-html # Purpose: Installs the requests-html library.\n",
        "\n",
        "!pip install requests  # Correct package name; built for making HTTP requests and handling responses easily.\n",
        "\n",
        "!pip install bs4 # Purpose: Installs the beautifulsoup4 library.\n",
        "\n",
        "# !pip install re  # re is a built-in module and does not need to be installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:06.904446Z",
          "iopub.status.busy": "2022-12-26T10:05:06.903610Z",
          "iopub.status.idle": "2022-12-26T10:05:06.918106Z",
          "shell.execute_reply": "2022-12-26T10:05:06.916982Z",
          "shell.execute_reply.started": "2022-12-26T10:05:06.904409Z"
        },
        "trusted": true,
        "id": "BPUO7soCjaHB"
      },
      "outputs": [],
      "source": [
        "import re # it is included in the Python standard library; need not to install Unlike external libraries, such as requests or pandas.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import requests # Sending HTTP requests and handle responses.\n",
        "\n",
        "from bs4 import BeautifulSoup # Parsing HTML and XML documents.\n",
        "\n",
        "# deque is helpful in opening the urls in a structured manner\n",
        "from collections import deque # double-ended queue, which allows for efficient appends and pops from both ends.It is useful for implementing queues and breadth-first search (BFS) algorithms.\n",
        "\n",
        "from urllib.parse import urlsplit # is helpful in parsing URLs into their components, such as scheme, netloc, path, query, and fragment.\n",
        "\n",
        "from requests_html import HTMLSession # HTMLSession is similar to requests but with added functionality for rendering JavaScript content; where JavaScript execution is required.\n",
        "\n",
        "import threading # is used for running multiple threads (tasks) simultaneously.\n",
        "\n",
        "import time # time-related tasks, such as pausing execution (sleep), measuring execution time, and getting the current time.\n",
        "\n",
        "from tqdm import tqdm # Creating progress bars for long-running tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:06.921811Z",
          "iopub.status.busy": "2022-12-26T10:05:06.921045Z",
          "iopub.status.idle": "2022-12-26T10:05:06.933536Z",
          "shell.execute_reply": "2022-12-26T10:05:06.931924Z",
          "shell.execute_reply.started": "2022-12-26T10:05:06.921767Z"
        },
        "trusted": true,
        "id": "O8XrpB4WjaHF"
      },
      "outputs": [],
      "source": [
        "#user_url = \"https://www.thapar.edu/sitemap.xml\"\n",
        "#url = [\"https://www.thapar.edu\"]\n",
        "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:06.936434Z",
          "iopub.status.busy": "2022-12-26T10:05:06.936048Z",
          "iopub.status.idle": "2022-12-26T10:05:09.351623Z",
          "shell.execute_reply": "2022-12-26T10:05:09.350425Z",
          "shell.execute_reply.started": "2022-12-26T10:05:06.936398Z"
        },
        "trusted": true,
        "id": "xw51GoK6jaHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9dff4b-bf65-49a2-b768-a9b66e4ac104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ac4de13b4d03>:4: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  soup = BeautifulSoup(xml) # Parse XML\n"
          ]
        }
      ],
      "source": [
        "def get_urls_of_xml(xml_url):\n",
        "    r = requests.get(xml_url) # HTTP GET Request\n",
        "    xml = r.text # Get XML Content\n",
        "    soup = BeautifulSoup(xml) # Parse XML\n",
        "\n",
        "    links_arr = [] # Initialize List for Links\n",
        "    for link in soup.findAll('loc'): # Extract URLs\n",
        "        linkstr = link.getText('', True)\n",
        "        links_arr.append(linkstr)\n",
        "\n",
        "    return links_arr # Return URLs\n",
        "\n",
        "links_data_arr = get_urls_of_xml(\"https://thapar.edu/sitemap.xml\") # Call the Function\n",
        "#print(links_data_arr) # would print the list of URLs extracted from the sitemap to the console.\n",
        "\n",
        "# Optimization 1: Limit the number of URLs to process\n",
        "links_data_arr = links_data_arr[:10]  # Process only the first 10 URLs for demonstration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:09.357183Z",
          "iopub.status.busy": "2022-12-26T10:05:09.356725Z",
          "iopub.status.idle": "2022-12-26T10:05:09.364213Z",
          "shell.execute_reply": "2022-12-26T10:05:09.362512Z",
          "shell.execute_reply.started": "2022-12-26T10:05:09.357144Z"
        },
        "trusted": true,
        "id": "2p6hNPpAjaHM"
      },
      "outputs": [],
      "source": [
        "session = HTMLSession()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:17.089462Z",
          "iopub.status.busy": "2022-12-26T10:05:17.089017Z",
          "iopub.status.idle": "2022-12-26T10:17:47.278602Z",
          "shell.execute_reply": "2022-12-26T10:17:47.277052Z",
          "shell.execute_reply.started": "2022-12-26T10:05:17.089423Z"
        },
        "trusted": true,
        "id": "i1gl4dsJjaHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8d0246-d3f5-49a9-d769-76c5cbf8074b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\n"
          ]
        }
      ],
      "source": [
        "email=set() # Initialize an Empty Set for Emails\n",
        "for i in tqdm(links_data_arr): # Iterate Over URLs with Progress Bar\n",
        "        #requests.get(f'{i}', verify=False)\n",
        "        r = session.get(i) # Send GET Request\n",
        "        for re_match in re.finditer(EMAIL_REGEX, r.html.raw_html.decode()): # Find Email Addresses in HTML Content\n",
        "            email.add(((re_match.group())).replace(\"-\",\"\")) # Add Email Addresses to Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:18:56.632354Z",
          "iopub.status.busy": "2022-12-26T10:18:56.631963Z",
          "iopub.status.idle": "2022-12-26T10:18:56.641790Z",
          "shell.execute_reply": "2022-12-26T10:18:56.640417Z",
          "shell.execute_reply.started": "2022-12-26T10:18:56.632323Z"
        },
        "trusted": true,
        "id": "QY1HjTyfjaHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53229967-8ff5-442d-bee6-0a6517bef1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              0\n",
            "0               info@thapar.edu\n",
            "1         admissions@thapar.edu\n",
            "2                tpo@thapar.edu\n",
            "3        karun.verma@thapar.edu\n",
            "4  technical_support@thapar.edu\n",
            "5          ajaykumar@thapar.edu\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(email)\n",
        "print(df)\n",
        "df.to_csv('Emails.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}